from bs4 import BeautifulSoup
from langchain_community.document_loaders import AsyncHtmlLoader
from langchain.text_splitter import (
    RecursiveCharacterTextSplitter,
)
from langchain_community.document_loaders import UnstructuredFileLoader
from langchain.vectorstores.faiss import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.embeddings import CacheBackedEmbeddings
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain.storage import LocalFileStore
from langchain.callbacks.base import BaseCallbackHandler
import streamlit as st
import os

os.makedirs("./.cache/files", exist_ok=True)
file_path = "./.cache/files/container.txt"
cache_dir = LocalFileStore("./.cache/embeddings/revenue")
splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
    chunk_size=2000,
    chunk_overlap=200,
)

st.set_page_config(
    page_title="êµ­ì„¸ì²­ GPT",
    page_icon="ğŸ“ƒ",
)


class ChatCallbackHandler(BaseCallbackHandler):
    message = ""

    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        save_message(self.message, "ai")

    def on_llm_new_token(self, token, *args, **kwargs):
        self.message += token
        self.message_box.markdown(self.message)


llm = ChatOpenAI(
    temperature=0.1,
    model_name="gpt-3.5-turbo-0125",
    streaming=True,
    callbacks=[
        ChatCallbackHandler(),
    ],
)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            ë˜ë„ë¡ contextì˜ ë‚´ìš©ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
            ë‹µë³€í•  ìˆ˜ ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” ë‹µë³€ì„ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”
            ë‹µë³€í•  ìˆ˜ ì—†ë‹¤ë©´ 'ì§ˆë¬¸ì— ëŒ€í•œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤' ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
            
            Context: {context}
            """,
        ),
        ("human", "{question}"),
    ]
)


@st.cache_data(show_spinner="Embedding file...")
def load_website(target_urls):
    loader = AsyncHtmlLoader(target_urls)
    loader.requests_per_second = 1
    docs = loader.load()
    container = ""
    for doc in docs:
        html_content = doc.page_content
        soup = BeautifulSoup(html_content, "html.parser")

        # classëª…ì´ 'locationWrap'ì¸ ìš”ì†Œ ì œê±°
        for location_wrap in soup.find_all(class_="locationWrap"):
            location_wrap.decompose()

        # classëª…ì´ 'zoomBox'ì¸ ìš”ì†Œ ì œê±°
        for zoom_box in soup.find_all(class_="zoomBox"):
            zoom_box.decompose()

        if container != "":
            container = container + "\n\n"

        container = (
            soup.find(id="container").get_text().replace("\n", " ").replace("\xa0", " ")
        )

        with open(file_path, "a", encoding="utf-8") as file:
            result_text = splitter.split_text(container)
            if result_text:
                # ë¦¬ìŠ¤íŠ¸ì˜ í•­ëª©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
                combined_text = " ".join(result_text)
                file.write(combined_text)
                file.write("\n\n---\n\n")


def get_contents():
    loader = UnstructuredFileLoader(file_path)
    result = loader.load_and_split(text_splitter=splitter)
    embeddings = OpenAIEmbeddings()
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)
    vector_store = FAISS.from_documents(result, cached_embeddings)
    retriever = vector_store.as_retriever()
    return retriever


def get_urls():
    url = [
        "https://www.nts.go.kr/nts/nurisitemap.do?mi=6789",  # ì „ì²´í¬íƒˆ
        "https://www.nts.go.kr/nts/cm/cntnts/cntntsView.do?mi=12242&cntntsId=8631",  # ì§€ê¸‰ëª…ì„¸ì„œ ì œì¶œ
        "https://www.nts.go.kr/nts/cm/cntnts/cntntsView.do?mi=6769&cntntsId=8165",  # ê·¼ë¡œì†Œë“
        "https://www.nts.go.kr/nts/cm/cntnts/cntntsView.do?mi=6441&cntntsId=7877",  # í‡´ì§ì†Œë“
        "https://www.nts.go.kr/nts/cm/cntnts/cntntsView.do?mi=6449&cntntsId=7885",  # ì—°ê¸ˆì†Œë“
        "https://www.nts.go.kr/nts/cm/cntnts/cntntsView.do?mi=6454&cntntsId=7890",  # ê¸°íƒ€ì†Œë“
        "https://www.nts.go.kr/nts/cm/cntnts/cntntsView.do?mi=6464&cntntsId=7900",  # ì‚¬ì—…ì†Œë“
        "https://www.nts.go.kr/nts/cm/cntnts/cntntsView.do?mi=6469&cntntsId=7905",  # ê¸ˆìœµ(ì´ìÂ·ë°°ë‹¹)ì†Œë“
        "https://www.nts.go.kr/nts/cm/cntnts/cntntsView.do?mi=6480&cntntsId=7916",  # ë¹„ê±°ì£¼ì ì›ì²œì§•ìˆ˜
    ]
    loader = AsyncHtmlLoader(url)
    docs = loader.load()
    print("Extracting content with LLM")

    all_urls = []

    for doc in docs:
        html_content = doc.page_content
        soup = BeautifulSoup(html_content, "html.parser")
        urls = [a.get("href") for a in soup.find_all("a", href=True)]
        filtered_urls = [url for url in urls if url.startswith("/nts")]
        filtered_urls = list(set(filtered_urls))
        all_urls += filtered_urls
        target_urls = [f"https://nts.go.kr{all_url}" for all_url in all_urls]
    target_urls = list(set(target_urls))
    return target_urls


def paint_history():
    for message in st.session_state["messages"]:
        send_message(
            message["message"],
            message["role"],
            save=False,
        )


def save_message(message, role):
    st.session_state["messages"].append({"message": message, "role": role})


def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)


def format_docs(docs):
    return "\n\n".join(document.page_content for document in docs)


def reload_page():
    st.experimental_rerun()


# ì´ˆê¸°í™” ë²„íŠ¼
if st.button("ì´ˆê¸°í™”"):
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    reload_page()

st.title("êµ­ì„¸ì²­AI")

st.markdown(
    """
ì•ˆë…•í•˜ì„¸ìš”!
            
êµ­ì„¸ì²­ ì‚¬ì´íŠ¸ì˜ ë‚´ìš©ì„ AIì—ê²Œ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆëŠ” êµ­ì„¸ì²­AI(ChatGPT3.5) ì…ë‹ˆë‹¤
    """
)

if not os.path.exists(file_path):
    final_urls = get_urls()
    contents = load_website(final_urls)


if "messages" not in st.session_state:
    st.session_state["messages"] = []

retriever = get_contents()

if retriever:
    send_message("ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”", "ai", save=False)
    paint_history()
    message = st.chat_input("êµ­ì„¸ì²­ì— ëŒ€í•´ ê¶ê¸ˆí•œê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”")
    if message:
        send_message(message, "human")
        chain = (
            {
                "context": retriever | RunnableLambda(format_docs),
                "question": RunnablePassthrough(),
            }
            | prompt
            | llm
        )
        with st.chat_message("ai"):
            chain.invoke(message)
